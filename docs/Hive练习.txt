Hive操作实战：

启动：
nohup hive --service metastore &
nohup hive --service hiveserver2 &

连接：beeline ： !connect jdbc:hive2://master:10000/default hadoopuser hadoopuser
!connect jdbc:hive2://dev-bigdata1:10000/default root root

使用Tez引擎
SET hive.execution.engine=tez;

Hive练习一：
1.建表
create table if not exists user_dimension(
uid STRING,
name STRING,
gender STRING,
birth DATE,
province STRING
)ROW FORMAT DELIMITED
FIELDS TERMINATED BY ',';

Hive练习二：
create table if not exists brand_dimension(
bid STRING,
category STRING,
brand STRING
)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ',';

create table if not exists record (
rid STRING,
uid STRING,
bid STRING,
price INT,
source_province STRING,
target_province STRING,
site STRING,
express_number STRING,
express_company STRING,
trancation_date DATE
)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ',';

describe user_dimension;
show create table user_dimension;

不同年龄消费情况：join表
select birth,sum(price) as total from record join user_dimension on record.uid = user_dimension.uid group by birth order by total desc;

2.加载数据
本地：load data local inpath '/app/user.data' overwrite into table user_dimension;
HDFS：load data inpath '/test/user.data' overwrite into table user_dimension;

select * from user_dimension;

3.查询数据

练习三：



Hive联系四：
create table if not exists stocks(
ymd DATE,
price_open FLOAT,
price_high FLOAT,
price_low FLOAT,
price_close FLOAT,
volumn INT,
price_adj_close FLOAT
)
partitioned by (exchanger STRING, symbol STRING)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ',';

load data local inpath '/app/stocks.csv' overwrite into table stocks partition(exchanger="NASDAQ",symbol="AAPL");

loAD data local inpath '/app/stocks-intc.csv' overwrite into table stocks partition(exchanger="NASDAQ",symbol="INTC");

select * from stocks where exchanger = 'NASDAQ' AND symbol = 'AAPL' LIMIT 10;

总结：drop外部表只删除元数据，不会删除数据文件，相对更加安全。

练习五：分区表
create table if not exists record_partition (
rid STRING,
uid STRING,
bid STRING,
price INT,
source_province STRING,
target_province STRING,
site STRING,
express_number STRING,
express_company STRING
)
partitioned by(trancation_date DATE) 
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ',';

开启动态分区：
set hive.exec.dynamic.partition.mode=nonstrict；

insert into table record_partition partition(trancation_date) select * from record;

Hive练习六：
create external table if not exists stocks_external(
ymd DATE,
price_open FLOAT,
price_high FLOAT,
price_low FLOAT,
price_close FLOAT,
volumn INT,
price_adj_close FLOAT
)
partitioned by (exchanger STRING, symbol STRING)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ',' 
LOCATION '/user/bigdata/stocks';

alter table stocks_external add partition(exchanger="NASDAQ",symbol="AAPL") location '/user/bigdata/stocks/NASDAQ/AAPL';
alter table stocks_external add partition(exchanger="NYSE",symbol="IBM") 
location '/user/bigdata/stocks/NYSE/IBM';

总结：减少不必要的暴力扫描，对表进行分区，选择离散字段进行分区。

Hive练习七：
create table if not exists record (
rid STRING,
uid STRING,
bid STRING,
price INT,
source_province STRING,
target_province STRING,
site STRING,
express_number STRING,
express_company STRING,
trancation_date DATE
)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ',';

load data local inpath '/app/record.data' overwrite into table record;

create table if not exists record_orc (
rid STRING,
uid STRING,
bid STRING,
price INT,
source_province STRING,
target_province STRING,
site STRING,
express_number STRING,
express_company STRING,
trancation_date DATE
)
stored as orc;

create table record_parquet like record_orc stored as parquet;

insert into table record_orc select * from record;

select count(*) from record where trancation_date = '2017-04-01';

总结：ORC、PARQUET、TEXT数据存储格式效果差数量级。ORC > PARQUET >> TEXTFILE














